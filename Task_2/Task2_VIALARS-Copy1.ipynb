{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torchcrf import CRF\n",
    "\n",
    "from gensim.models.fasttext import FastText\n",
    "from elmoformanylangs import Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], device='cuda:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "torch.tensor([1.], device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMED_ENTITIES = ['O', 'B-ORG', 'I-ORG', 'B-PER', 'I-PER', 'B-LOC', 'I-LOC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to load data from document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_label(spans, objects, tokens_number):\n",
    "    type_ent = {'Org' : 'ORG', 'Person' : 'PER', 'Location' : 'LOC', 'LocOrg' : 'LOC'}\n",
    "    labels_named = []\n",
    "    labels = []\n",
    "    spans_list = []\n",
    "    wait = []  \n",
    "    \n",
    "    spans_number = []\n",
    "\n",
    "    for s in spans:\n",
    "        num_of_tokens = int(s[5])\n",
    "        r_tks = s[7:7+num_of_tokens]\n",
    "        spans_number.append(r_tks)\n",
    "    \n",
    "    for tk in tokens_number:\n",
    "        tk_labels = 'O'\n",
    "        tk_spans = []\n",
    "        for i in range(len(spans_number)):\n",
    "            r_tks = spans_number[i]\n",
    "            \n",
    "            if(tk in r_tks and spans[i][1] != 'job'):\n",
    "                tk_spans.append(deepcopy(spans[i]))\n",
    "        \n",
    "        if(len(tk_spans) != 0):\n",
    "            spans_list.append(tk_spans)\n",
    "        else:\n",
    "            spans_list.append(['O'])\n",
    "\n",
    "    for i in range(len(spans_list)):\n",
    "        if(len(spans_list[i]) == 1):\n",
    "            labels_named.append(spans_list[i][0])\n",
    "        else:\n",
    "            rm = []\n",
    "            l2 = deepcopy(spans_list[i])\n",
    "            \n",
    "            for j in l2:\n",
    "                rm.append((j.pop(0), j.pop(0)))\n",
    "                \n",
    "            unique_data = [list(x) for x in set(tuple(x) for x in l2)]\n",
    "            if (len(unique_data) == 1):\n",
    "                i_unique = l2.index(unique_data[0])\n",
    "                labels_named.append(spans_list[i][i_unique])\n",
    "            else:\n",
    "                i_near = np.arange(i-4, i+4)\n",
    "                i_near = np.delete(i_near, 4)\n",
    "                \n",
    "                for j in range(len(i_near)):\n",
    "                    if (i_near[j] >= 0 and i_near[j] < len(spans_list)):\n",
    "                        if (j < 4):\n",
    "                            to_look = [labels_named[i_near[j]]]\n",
    "                        else:\n",
    "                            to_look = spans_list[i_near[j]]\n",
    "\n",
    "                        corr = []\n",
    "                        for sp in spans_list[i]:\n",
    "                            if (sp in to_look):\n",
    "                                corr.append(deepcopy(sp))\n",
    "\n",
    "                        if (len(corr) == 1):\n",
    "                            ind = spans_list[i].index(corr[0])\n",
    "                            labels_named.append(spans_list[i][ind])\n",
    "                            break\n",
    "                            \n",
    "                        rm = []\n",
    "                        for c in corr:\n",
    "                            rm.append(c.pop(1))\n",
    "                        unique_data = [list(x) for x in set(tuple(x) for x in corr)]                        \n",
    "                        if(len(unique_data) == 1):\n",
    "                            i_unique = corr.index(unique_data[0])\n",
    "                            labels_named.append(spans_list[i][i_unique])\n",
    "                            break\n",
    "\n",
    "    ignore = ['job', 'prj_descr', 'prj_name', 'facility_descr', 'geo_adj']                        \n",
    "    for l in labels_named:\n",
    "        if (l == 'O' or l[1] in ignore):\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            if (l[1] not in ignore):\n",
    "                id_obj = l[0]\n",
    "                l_obj = []\n",
    "\n",
    "                for o in objects:\n",
    "                    if(id_obj in o):\n",
    "                        index_i = o.index('#')\n",
    "                        obj = o[1:index_i]\n",
    "                        l_obj.append(obj)\n",
    "\n",
    "                if (len(l_obj) == 1):\n",
    "                    if (l_obj[0] in wait):\n",
    "                        tk_labels = \"I-\" + type_ent.get(l_obj[0][0])\n",
    "                    else:\n",
    "                        tk_labels = \"B-\" + type_ent.get(l_obj[0][0])\n",
    "                        wait.append(l_obj[0])\n",
    "\n",
    "                else:\n",
    "                    for p in l_obj:\n",
    "                        if (p in wait):\n",
    "                            tk_labels = \"I-\" + type_ent.get(p[0])\n",
    "                            break\n",
    "                        else:\n",
    "                            wait.append(p)\n",
    "                labels.append(NAMED_ENTITIES.index(tk_labels))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, test_data = False):\n",
    "    list_texts = []\n",
    "    list_labels = []\n",
    "    list_books = []\n",
    "    \n",
    "    list_tokens_file = list(filter(lambda f : f.endswith('.tokens'), os.listdir(path)))\n",
    "    list_spans_file = list(filter(lambda f : f.endswith('.spans'), os.listdir(path)))\n",
    "    list_objects_file = list(filter(lambda f : f.endswith('.objects'), os.listdir(path)))\n",
    "    \n",
    "    for i in range(len(list_tokens_file)):\n",
    "        text_i = []\n",
    "        tokens_number = []\n",
    "        token_file = open(path + list_tokens_file[i], 'r', encoding = 'utf-8')\n",
    "        spans_file = open(path + list_spans_file[i], 'r', encoding = 'utf-8')\n",
    "        objects_file = open(path + list_objects_file[i], 'r', encoding = 'utf-8')\n",
    "        \n",
    "        tokens = list(map(lambda l: l.split(), token_file.readlines()))\n",
    "        spans = list(map(lambda l : l.split(), spans_file.readlines()))\n",
    "        objects = list(map(lambda l : l.split(), objects_file.readlines()))\n",
    "        \n",
    "        length = 0\n",
    "        for j in range(len(tokens)):\n",
    "            if(len(tokens[j]) == 0):\n",
    "                if(test_data == False):                    \n",
    "                    list_labels.append(compute_label(spans, objects, tokens_number))\n",
    "                    \n",
    "                list_texts.append(text_i)\n",
    "                text_i = []\n",
    "                tokens_number = []\n",
    "            else:\n",
    "                text_i.append(tokens[j][-1])\n",
    "                tokens_number.append(tokens[j][0])\n",
    "                length += 1\n",
    "        \n",
    "        if(test_data == True):\n",
    "            list_books.append((list_tokens_file[i].replace('.tokens', ''), length))\n",
    "            list_labels.append(compute_label(spans, objects, tokens_number))\n",
    "        \n",
    "        token_file.close()\n",
    "        spans_file.close()\n",
    "        objects_file.close()\n",
    "        \n",
    "    if (test_data == True):\n",
    "        return list_books, list_texts, list_labels\n",
    "    else:\n",
    "        return list_texts, list_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "entite = {'B-ORG' : 'org', 'I-ORG' : 'org', 'B-PER' : 'per', 'I-PER' : 'per', 'B-LOC' : 'loc', 'I-LOC' : 'loc'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to create file for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_eval(path_dir_test, path_dir_eval, filename, predictions):\n",
    "    entite = {'B-ORG' : 'org', 'I-ORG' : 'org', 'B-PER' : 'per', 'I-PER' : 'per', 'B-LOC' : 'loc', 'I-LOC' : 'loc'}\n",
    "    m = 0\n",
    "    for i in range(len(filename)):\n",
    "        name = filename[i][0]\n",
    "        length = filename[i][1]\n",
    "        \n",
    "        text_predict = []\n",
    "        som = 0\n",
    "        for k in range(m, len(predictions)):\n",
    "            som += len(predictions[m])\n",
    "            text_predict += predictions[m]\n",
    "            m += 1\n",
    "            if(som == length):\n",
    "                break       \n",
    "        \n",
    "        token_file = open(path_dir_test + name + '.tokens', 'r', encoding = 'utf-8')\n",
    "        tokens_b = list(map(lambda l: l.split(), token_file.readlines()))\n",
    "        tokens = []        \n",
    "        for t in tokens_b:\n",
    "            if (t != []):\n",
    "                tokens.append(t)\n",
    "        \n",
    "        eval_f = open(path_dir_eval + name + '.task1', 'w+', encoding = 'utf-8')\n",
    "        \n",
    "        to_write = []\n",
    "        size = 0\n",
    "        for j in range(len(tokens)):\n",
    "            label_j = NAMED_ENTITIES[text_predict[j]]\n",
    "\n",
    "            if (label_j != 'O'):\n",
    "                if (label_j[0] == 'B'):\n",
    "                    if(to_write != []):\n",
    "                        to_write.append(str(size))\n",
    "                        eval_f.write(to_write[0] + ' ' + to_write[1] + ' '  + to_write[2] + '\\n')\n",
    "\n",
    "                        to_write = []\n",
    "                        \n",
    "                    start = tokens[j][1]\n",
    "                    size = int(tokens[j][2])\n",
    "                    ent = entite[label_j]\n",
    "                    \n",
    "                    to_write.append(ent)\n",
    "                    to_write.append(start)\n",
    "                else:\n",
    "                    ent = entite[label_j]\n",
    "                    \n",
    "                    if(to_write != []):\n",
    "                        if(ent != to_write[0]):\n",
    "                            to_write.append(str(size))\n",
    "                            eval_f.write(to_write[0] + ' ' + to_write[1] + ' '  + to_write[2] + '\\n')\n",
    "                            to_write = []\n",
    "                        else:\n",
    "                            size += 1\n",
    "                            size += int(tokens[j][2])\n",
    "                        \n",
    "                    if(to_write == []):\n",
    "                        start = tokens[j][1]\n",
    "                        size = int(tokens[j][2])\n",
    "                        to_write.append(ent)\n",
    "                        to_write.append(start)                \n",
    "                    \n",
    "        eval_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__ (self, data, label, model_vect_size):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.model_vect_size = model_vect_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, index):       \n",
    "        text = self.data[index] \n",
    "        seq_len = len(text)\n",
    "        \n",
    "        miss_data = 90 - seq_len\n",
    "        data_to_add = np.zeros((miss_data, self.model_vect_size))        \n",
    "        text = np.concatenate([text, data_to_add])\n",
    "        \n",
    "        mask = np.ones(seq_len)\n",
    "        mask = np.concatenate([mask, np.zeros(miss_data)])\n",
    "        \n",
    "        \n",
    "        if (self.label != None):\n",
    "            t_label = self.label[index]\n",
    "            t_label = np.concatenate([t_label, np.zeros(miss_data)])            \n",
    "            return text, t_label, mask\n",
    "        \n",
    "        else:\n",
    "            return text, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-LSTM CRF network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM_CRF(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_dim, num_tag, batch_first = False):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.lstm = nn.LSTM(embed_size, hidden_dim // 2, num_layers=1, bidirectional=True, \n",
    "                            batch_first = batch_first)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, num_tag)\n",
    "\n",
    "        self.crf = CRF(num_tag, batch_first=batch_first)\n",
    "        \n",
    "        self.hidden = self.init_hidden(batch_size)\n",
    "    \n",
    "    def init_hidden(self, size):\n",
    "        return (torch.zeros(2, size, self.hidden_dim // 2, device = device),\n",
    "                torch.zeros(2, size, self.hidden_dim // 2, device = device))\n",
    "\n",
    "    def forward(self, x, y, mask):\n",
    "        self.hidden = self.init_hidden(x.shape[0])\n",
    "        x, _ = self.lstm(x, self.hidden)\n",
    "        x = self.hidden2tag(x)\n",
    "        x = self.crf(x, y, mask=mask)\n",
    "        return -x\n",
    "    \n",
    "    def predict(self, x, mask):\n",
    "        self.hidden = self.init_hidden(x.shape[0])\n",
    "        x, _ = self.lstm(x, self.hidden)\n",
    "        x = self.hidden2tag(x)\n",
    "        return self.crf.decode(x, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to train and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for i_step, (x, y, mask) in enumerate(train_loader):\n",
    "            model.zero_grad()        \n",
    "            x_gpu = x.to(device, dtype=torch.float)\n",
    "            y_gpu = y.to(device, dtype=torch.long)\n",
    "            m_gpu = mask.to(device, dtype=torch.uint8)\n",
    "\n",
    "            loss = model(x_gpu, y_gpu, m_gpu)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()        \n",
    "            optimizer.step() \n",
    "\n",
    "def predict(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for i_step, (x, mask) in enumerate(test_loader):\n",
    "            x_gpu = x.to(device, dtype=torch.float)\n",
    "            m_gpu = mask.to(device, dtype=torch.uint8)\n",
    "            \n",
    "            predict = model.predict(x_gpu, mask = m_gpu)\n",
    "            predictions += predict\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train, labels_train = load_data(\"data/devset/\")\n",
    "books_name, texts_test, labels_test = load_data(\"data/testset/\", test_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Using FastText model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading FastText model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-18 22:11:28,413 WARNING: this function is deprecated, use smart_open.open instead\n",
      "2019-05-18 22:11:28,424 INFO: loading 2000000 words for fastText model from cc.ru.300.bin\n",
      "2019-05-18 22:12:28,413 INFO: resetting layer weights\n",
      "2019-05-18 22:12:28,756 INFO: Total number of ngrams is 0\n",
      "2019-05-18 22:12:29,022 INFO: Updating model with new vocabulary\n",
      "2019-05-18 22:12:41,927 INFO: New added 2000000 unique words (50% of original 4000000) and increased the count of 2000000 pre-existing words (50% of original 4000000)\n",
      "2019-05-18 22:12:53,666 INFO: deleting the raw counts dictionary of 2000000 items\n",
      "2019-05-18 22:12:53,666 INFO: sample=1e-05 downsamples 6340 most-common words\n",
      "2019-05-18 22:12:53,675 INFO: downsampling leaves estimated 102264634653 word corpus (100.7% of prior 101572190356)\n",
      "2019-05-18 22:22:53,789 INFO: loaded (4000000, 300) weight matrix for fastText model from cc.ru.300.bin\n"
     ]
    }
   ],
   "source": [
    "fasttext_model = FastText.load_fasttext_format('cc.ru.300.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word to vector function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gensim_convert_to_vectors(model, list_text):\n",
    "    list_vect = []\n",
    "    for sentence in list_text:\n",
    "        sentence_vect = []\n",
    "        for word in sentence:\n",
    "            if word.lower() in model.wv.vocab:\n",
    "                sentence_vect.append(model.wv[word])\n",
    "            else:\n",
    "                sentence_vect.append(np.zeros(model.vector_size))\n",
    "        list_vect.append(np.array(sentence_vect))\n",
    "        \n",
    "    return list_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train1 = deepcopy(texts_train)\n",
    "labels_train1 = deepcopy(labels_train)\n",
    "\n",
    "texts_test1 = deepcopy(texts_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train1 = gensim_convert_to_vectors(fasttext_model, texts_train1)\n",
    "texts_test1 = gensim_convert_to_vectors(fasttext_model, texts_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_dataset_train1 = NERDataset(texts_train1, labels_train1, fasttext_model.vector_size)\n",
    "texts_train_loader1 = torch.utils.data.DataLoader(texts_dataset_train1, batch_size = batch_size)\n",
    "\n",
    "texts_dataset_test1 = NERDataset(texts_test1, None, fasttext_model.vector_size)\n",
    "texts_test_loader1 = torch.utils.data.DataLoader(texts_dataset_test1, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm_crf1 = BiLSTM_CRF(embed_size = fasttext_model.vector_size, \n",
    "                         hidden_dim = 10, \n",
    "                         num_tag = 7,\n",
    "                         batch_first = True)\n",
    "\n",
    "bilstm_crf1.type(torch.cuda.FloatTensor)\n",
    "bilstm_crf1.to(device)\n",
    "\n",
    "optimizer1 = optim.RMSprop(bilstm_crf1.parameters(), lr = 1e-2, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load the standard of book_3954:\n",
      "Unknown mention tag: Facility\n",
      "Type    P        R        F1       TP1      TP2      In Std.  In Test.\n",
      "per        0.8721   0.7612   0.8129  1017.75  1017.75     1337     1167\n",
      "loc        0.7865   0.8487   0.8164  1042.17  1042.17     1228     1325\n",
      "org        0.7128   0.5543   0.6236   872.43   872.43     1574     1224\n",
      "overall    0.7891   0.7085   0.7466  2932.34  2932.34     4139     3716\n",
      "Wall time: 4min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_model(bilstm_crf1, texts_train_loader1, optimizer1, num_epochs = 20)\n",
    "\n",
    "predictions1 = predict(bilstm_crf1, texts_test_loader1)\n",
    "\n",
    "create_file_eval('data/testset/', 'data/eval/', books_name, predictions1)\n",
    "\n",
    "!python scripts/t1_eval.py -s data/testset -t data/eval -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Using ELMo model\n",
    "\n",
    "Using model from : https://github.com/HIT-SCIR/ELMoForManyLangs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading ELMo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-18 22:23:37,848 INFO: char embedding size: 3896\n",
      "2019-05-18 22:23:39,892 INFO: word embedding size: 329681\n",
      "2019-05-18 22:23:47,451 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(329681, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(3896, 50, padding_idx=3893)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "elmo_model = Embedder('russian.model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence to vector function\n",
    "We could give the list of text to the ELMo model but my graphic card is not enough powerful so I am splitting the list into parts and giving each part to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elmo_convert_to_vectors(model, list_text):\n",
    "    list_vect = []\n",
    "    list_sentence = [list_text[15*i:15*(i+1)] for i in range(int(len(list_text)/15) + 1)]\n",
    "    if (list_sentence[-1] == []):\n",
    "        list_sentence.pop(-1)\n",
    "\n",
    "    for sentences in list_sentence:\n",
    "        sentences_vect = model.sents2elmo(sentences)\n",
    "        list_vect += sentences_vect\n",
    "    \n",
    "    return list_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train2 = deepcopy(texts_train)\n",
    "labels_train2 = deepcopy(labels_train)\n",
    "\n",
    "texts_test2 = deepcopy(texts_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch size, Embedding size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "elmo_embedding_size = elmo_model.config.get('token_embedder').get('filters')[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-18 22:23:58,046 INFO: 1 batches, avg len: 32.2\n",
      "2019-05-18 22:24:03,410 INFO: 1 batches, avg len: 19.1\n",
      "2019-05-18 22:24:05,123 INFO: 1 batches, avg len: 22.3\n",
      "2019-05-18 22:24:06,390 INFO: 1 batches, avg len: 19.1\n",
      "2019-05-18 22:24:07,730 INFO: 1 batches, avg len: 22.4\n",
      "2019-05-18 22:24:08,988 INFO: 1 batches, avg len: 19.1\n",
      "2019-05-18 22:24:10,340 INFO: 1 batches, avg len: 26.1\n",
      "2019-05-18 22:24:12,336 INFO: 1 batches, avg len: 17.7\n",
      "2019-05-18 22:24:13,853 INFO: 1 batches, avg len: 16.3\n",
      "2019-05-18 22:24:14,829 INFO: 1 batches, avg len: 17.5\n",
      "2019-05-18 22:24:16,294 INFO: 1 batches, avg len: 22.0\n",
      "2019-05-18 22:24:18,004 INFO: 1 batches, avg len: 18.1\n",
      "2019-05-18 22:24:19,407 INFO: 1 batches, avg len: 25.0\n",
      "2019-05-18 22:24:21,291 INFO: 1 batches, avg len: 31.0\n",
      "2019-05-18 22:24:23,645 INFO: 1 batches, avg len: 26.5\n",
      "2019-05-18 22:24:25,471 INFO: 1 batches, avg len: 19.9\n",
      "2019-05-18 22:24:27,314 INFO: 1 batches, avg len: 16.2\n",
      "2019-05-18 22:24:28,536 INFO: 1 batches, avg len: 18.3\n",
      "2019-05-18 22:24:29,770 INFO: 1 batches, avg len: 16.8\n",
      "2019-05-18 22:24:30,728 INFO: 1 batches, avg len: 19.0\n",
      "2019-05-18 22:24:32,079 INFO: 1 batches, avg len: 26.6\n",
      "2019-05-18 22:24:33,587 INFO: 1 batches, avg len: 22.1\n",
      "2019-05-18 22:24:34,976 INFO: 1 batches, avg len: 25.2\n",
      "2019-05-18 22:24:36,609 INFO: 1 batches, avg len: 21.7\n",
      "2019-05-18 22:24:37,855 INFO: 1 batches, avg len: 22.1\n",
      "2019-05-18 22:24:39,404 INFO: 1 batches, avg len: 18.8\n",
      "2019-05-18 22:24:40,779 INFO: 1 batches, avg len: 22.7\n",
      "2019-05-18 22:24:42,103 INFO: 1 batches, avg len: 19.3\n",
      "2019-05-18 22:24:43,249 INFO: 1 batches, avg len: 24.0\n",
      "2019-05-18 22:24:44,673 INFO: 1 batches, avg len: 25.3\n",
      "2019-05-18 22:24:46,224 INFO: 1 batches, avg len: 23.1\n",
      "2019-05-18 22:24:47,856 INFO: 1 batches, avg len: 23.7\n",
      "2019-05-18 22:24:49,880 INFO: 1 batches, avg len: 23.6\n",
      "2019-05-18 22:24:53,204 INFO: 1 batches, avg len: 22.2\n",
      "2019-05-18 22:24:54,908 INFO: 1 batches, avg len: 19.5\n",
      "2019-05-18 22:24:56,670 INFO: 1 batches, avg len: 21.6\n",
      "2019-05-18 22:24:58,646 INFO: 1 batches, avg len: 19.3\n",
      "2019-05-18 22:24:59,852 INFO: 1 batches, avg len: 21.9\n",
      "2019-05-18 22:25:01,546 INFO: 1 batches, avg len: 25.3\n",
      "2019-05-18 22:25:03,145 INFO: 1 batches, avg len: 28.1\n",
      "2019-05-18 22:25:04,761 INFO: 1 batches, avg len: 24.7\n",
      "2019-05-18 22:25:06,573 INFO: 1 batches, avg len: 18.0\n",
      "2019-05-18 22:25:08,196 INFO: 1 batches, avg len: 21.5\n",
      "2019-05-18 22:25:09,417 INFO: 1 batches, avg len: 18.3\n",
      "2019-05-18 22:25:10,577 INFO: 1 batches, avg len: 19.3\n",
      "2019-05-18 22:25:11,800 INFO: 1 batches, avg len: 26.3\n",
      "2019-05-18 22:25:13,667 INFO: 1 batches, avg len: 15.8\n",
      "2019-05-18 22:25:14,796 INFO: 1 batches, avg len: 19.8\n",
      "2019-05-18 22:25:16,365 INFO: 1 batches, avg len: 24.4\n",
      "2019-05-18 22:25:17,572 INFO: 1 batches, avg len: 17.6\n",
      "2019-05-18 22:25:18,764 INFO: 1 batches, avg len: 19.8\n",
      "2019-05-18 22:25:20,033 INFO: 1 batches, avg len: 25.8\n",
      "2019-05-18 22:25:21,679 INFO: 1 batches, avg len: 20.2\n",
      "2019-05-18 22:25:23,373 INFO: 1 batches, avg len: 23.7\n",
      "2019-05-18 22:25:24,800 INFO: 1 batches, avg len: 17.5\n",
      "2019-05-18 22:25:26,160 INFO: 1 batches, avg len: 24.3\n",
      "2019-05-18 22:25:27,920 INFO: 1 batches, avg len: 23.1\n",
      "2019-05-18 22:25:29,472 INFO: 1 batches, avg len: 17.1\n",
      "2019-05-18 22:25:30,728 INFO: 1 batches, avg len: 21.1\n",
      "2019-05-18 22:25:33,060 INFO: 1 batches, avg len: 26.1\n",
      "2019-05-18 22:25:34,567 INFO: 1 batches, avg len: 21.0\n",
      "2019-05-18 22:25:36,060 INFO: 1 batches, avg len: 18.2\n",
      "2019-05-18 22:25:37,232 INFO: 1 batches, avg len: 19.3\n",
      "2019-05-18 22:25:38,614 INFO: 1 batches, avg len: 8.2\n",
      "2019-05-18 22:25:39,005 INFO: 1 batches, avg len: 11.1\n",
      "2019-05-18 22:25:40,087 INFO: 1 batches, avg len: 16.4\n",
      "2019-05-18 22:25:41,390 INFO: 1 batches, avg len: 9.7\n",
      "2019-05-18 22:25:42,585 INFO: 1 batches, avg len: 4.1\n",
      "2019-05-18 22:25:42,786 INFO: 1 batches, avg len: 6.1\n",
      "2019-05-18 22:25:43,615 INFO: 1 batches, avg len: 4.1\n",
      "2019-05-18 22:25:43,835 INFO: 1 batches, avg len: 4.2\n",
      "2019-05-18 22:25:44,099 INFO: 1 batches, avg len: 16.9\n",
      "2019-05-18 22:25:45,278 INFO: 1 batches, avg len: 13.8\n",
      "2019-05-18 22:25:46,594 INFO: 1 batches, avg len: 16.8\n",
      "2019-05-18 22:25:47,629 INFO: 1 batches, avg len: 17.5\n",
      "2019-05-18 22:25:48,806 INFO: 1 batches, avg len: 18.5\n",
      "2019-05-18 22:25:50,154 INFO: 1 batches, avg len: 18.9\n",
      "2019-05-18 22:25:51,566 INFO: 1 batches, avg len: 19.9\n",
      "2019-05-18 22:25:53,541 INFO: 1 batches, avg len: 14.6\n",
      "2019-05-18 22:25:54,420 INFO: 1 batches, avg len: 16.3\n",
      "2019-05-18 22:25:55,925 INFO: 1 batches, avg len: 11.2\n",
      "2019-05-18 22:25:56,866 INFO: 1 batches, avg len: 18.1\n",
      "2019-05-18 22:25:58,120 INFO: 1 batches, avg len: 23.5\n",
      "2019-05-18 22:26:01,019 INFO: 1 batches, avg len: 20.3\n",
      "2019-05-18 22:26:02,149 INFO: 1 batches, avg len: 17.5\n",
      "2019-05-18 22:26:03,544 INFO: 1 batches, avg len: 20.4\n",
      "2019-05-18 22:26:04,799 INFO: 1 batches, avg len: 19.2\n",
      "2019-05-18 22:26:06,148 INFO: 1 batches, avg len: 21.3\n",
      "2019-05-18 22:26:07,480 INFO: 1 batches, avg len: 15.9\n",
      "2019-05-18 22:26:08,531 INFO: 1 batches, avg len: 20.8\n",
      "2019-05-18 22:26:10,491 INFO: 1 batches, avg len: 20.5\n",
      "2019-05-18 22:26:11,903 INFO: 1 batches, avg len: 16.7\n",
      "2019-05-18 22:26:13,079 INFO: 1 batches, avg len: 19.7\n",
      "2019-05-18 22:26:14,444 INFO: 1 batches, avg len: 23.7\n",
      "2019-05-18 22:26:16,076 INFO: 1 batches, avg len: 16.9\n",
      "2019-05-18 22:26:17,423 INFO: 1 batches, avg len: 22.2\n",
      "2019-05-18 22:26:18,975 INFO: 1 batches, avg len: 25.3\n",
      "2019-05-18 22:26:20,764 INFO: 1 batches, avg len: 21.5\n",
      "2019-05-18 22:26:22,659 INFO: 1 batches, avg len: 18.0\n",
      "2019-05-18 22:26:23,835 INFO: 1 batches, avg len: 18.3\n",
      "2019-05-18 22:26:25,044 INFO: 1 batches, avg len: 20.0\n",
      "2019-05-18 22:26:26,676 INFO: 1 batches, avg len: 19.5\n",
      "2019-05-18 22:26:28,430 INFO: 1 batches, avg len: 17.7\n",
      "2019-05-18 22:26:30,044 INFO: 1 batches, avg len: 17.6\n",
      "2019-05-18 22:26:31,284 INFO: 1 batches, avg len: 12.6\n",
      "2019-05-18 22:26:32,162 INFO: 1 batches, avg len: 14.9\n",
      "2019-05-18 22:26:33,761 INFO: 1 batches, avg len: 17.6\n",
      "2019-05-18 22:26:34,876 INFO: 1 batches, avg len: 19.8\n",
      "2019-05-18 22:26:36,270 INFO: 1 batches, avg len: 16.6\n",
      "2019-05-18 22:26:37,931 INFO: 1 batches, avg len: 17.6\n",
      "2019-05-18 22:26:39,408 INFO: 1 batches, avg len: 20.9\n",
      "2019-05-18 22:26:40,912 INFO: 1 batches, avg len: 18.4\n",
      "2019-05-18 22:26:42,166 INFO: 1 batches, avg len: 18.6\n",
      "2019-05-18 22:26:43,342 INFO: 1 batches, avg len: 17.4\n",
      "2019-05-18 22:26:44,623 INFO: 1 batches, avg len: 17.0\n",
      "2019-05-18 22:26:45,667 INFO: 1 batches, avg len: 16.7\n",
      "2019-05-18 22:26:46,917 INFO: 1 batches, avg len: 20.7\n",
      "2019-05-18 22:26:48,833 INFO: 1 batches, avg len: 24.6\n",
      "2019-05-18 22:26:50,450 INFO: 1 batches, avg len: 20.4\n",
      "2019-05-18 22:26:52,108 INFO: 1 batches, avg len: 14.9\n",
      "2019-05-18 22:26:53,014 INFO: 1 batches, avg len: 16.6\n",
      "2019-05-18 22:26:54,288 INFO: 1 batches, avg len: 28.7\n",
      "2019-05-18 22:26:56,231 INFO: 1 batches, avg len: 21.1\n",
      "2019-05-18 22:26:58,003 INFO: 1 batches, avg len: 22.9\n",
      "2019-05-18 22:26:59,930 INFO: 1 batches, avg len: 26.4\n",
      "2019-05-18 22:27:01,579 INFO: 1 batches, avg len: 23.2\n",
      "2019-05-18 22:27:03,129 INFO: 1 batches, avg len: 14.6\n",
      "2019-05-18 22:27:04,574 INFO: 1 batches, avg len: 16.3\n",
      "2019-05-18 22:27:05,685 INFO: 1 batches, avg len: 22.1\n",
      "2019-05-18 22:27:07,443 INFO: 1 batches, avg len: 17.0\n",
      "2019-05-18 22:27:08,635 INFO: 1 batches, avg len: 18.9\n",
      "2019-05-18 22:27:10,610 INFO: 1 batches, avg len: 19.7\n",
      "2019-05-18 22:27:12,647 INFO: 1 batches, avg len: 15.9\n",
      "2019-05-18 22:27:13,996 INFO: 1 batches, avg len: 12.4\n",
      "2019-05-18 22:27:14,953 INFO: 1 batches, avg len: 17.5\n",
      "2019-05-18 22:27:16,537 INFO: 1 batches, avg len: 17.3\n",
      "2019-05-18 22:27:17,713 INFO: 1 batches, avg len: 10.6\n",
      "2019-05-18 22:27:18,418 INFO: 1 batches, avg len: 9.8\n",
      "2019-05-18 22:27:19,282 INFO: 1 batches, avg len: 15.1\n",
      "2019-05-18 22:27:20,519 INFO: 1 batches, avg len: 17.7\n",
      "2019-05-18 22:27:22,277 INFO: 1 batches, avg len: 21.5\n",
      "2019-05-18 22:27:24,393 INFO: 1 batches, avg len: 18.5\n",
      "2019-05-18 22:27:25,317 INFO: 1 batches, avg len: 18.1\n",
      "2019-05-18 22:27:26,698 INFO: 1 batches, avg len: 27.1\n",
      "2019-05-18 22:27:28,510 INFO: 1 batches, avg len: 28.9\n",
      "2019-05-18 22:27:30,346 INFO: 1 batches, avg len: 32.4\n",
      "2019-05-18 22:27:32,278 INFO: 1 batches, avg len: 23.3\n",
      "2019-05-18 22:27:34,694 INFO: 1 batches, avg len: 22.3\n",
      "2019-05-18 22:27:36,185 INFO: 1 batches, avg len: 23.2\n",
      "2019-05-18 22:27:37,971 INFO: 1 batches, avg len: 32.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-18 22:27:40,559 INFO: 1 batches, avg len: 23.0\n",
      "2019-05-18 22:27:42,378 INFO: 1 batches, avg len: 19.7\n",
      "2019-05-18 22:27:43,819 INFO: 1 batches, avg len: 13.7\n",
      "2019-05-18 22:27:45,202 INFO: 1 batches, avg len: 15.1\n",
      "2019-05-18 22:27:46,378 INFO: 1 batches, avg len: 18.0\n",
      "2019-05-18 22:27:47,724 INFO: 1 batches, avg len: 23.1\n",
      "2019-05-18 22:27:49,213 INFO: 1 batches, avg len: 23.2\n",
      "2019-05-18 22:27:51,442 INFO: 1 batches, avg len: 14.6\n",
      "2019-05-18 22:27:52,882 INFO: 1 batches, avg len: 14.0\n",
      "2019-05-18 22:27:53,860 INFO: 1 batches, avg len: 22.5\n",
      "2019-05-18 22:27:55,359 INFO: 1 batches, avg len: 18.5\n",
      "2019-05-18 22:27:57,385 INFO: 1 batches, avg len: 15.2\n",
      "2019-05-18 22:27:58,905 INFO: 1 batches, avg len: 17.6\n",
      "2019-05-18 22:28:00,145 INFO: 1 batches, avg len: 19.7\n",
      "2019-05-18 22:28:01,757 INFO: 1 batches, avg len: 16.8\n",
      "2019-05-18 22:28:03,467 INFO: 1 batches, avg len: 27.6\n",
      "2019-05-18 22:28:05,188 INFO: 1 batches, avg len: 21.8\n",
      "2019-05-18 22:28:06,918 INFO: 1 batches, avg len: 25.8\n",
      "2019-05-18 22:28:08,627 INFO: 1 batches, avg len: 21.6\n",
      "2019-05-18 22:28:10,273 INFO: 1 batches, avg len: 21.4\n",
      "2019-05-18 22:28:11,684 INFO: 1 batches, avg len: 19.1\n",
      "2019-05-18 22:28:12,939 INFO: 1 batches, avg len: 18.1\n",
      "2019-05-18 22:28:14,066 INFO: 1 batches, avg len: 19.2\n",
      "2019-05-18 22:28:15,338 INFO: 1 batches, avg len: 17.3\n",
      "2019-05-18 22:28:16,562 INFO: 1 batches, avg len: 15.0\n",
      "2019-05-18 22:28:17,533 INFO: 1 batches, avg len: 15.7\n",
      "2019-05-18 22:28:18,349 INFO: 1 batches, avg len: 15.3\n",
      "2019-05-18 22:28:19,382 INFO: 1 batches, avg len: 18.9\n",
      "2019-05-18 22:28:20,654 INFO: 1 batches, avg len: 18.5\n",
      "2019-05-18 22:28:21,829 INFO: 1 batches, avg len: 21.6\n",
      "2019-05-18 22:28:23,806 INFO: 1 batches, avg len: 22.5\n",
      "2019-05-18 22:28:25,389 INFO: 1 batches, avg len: 24.1\n",
      "2019-05-18 22:28:27,600 INFO: 1 batches, avg len: 24.1\n",
      "2019-05-18 22:28:29,092 INFO: 1 batches, avg len: 24.5\n",
      "2019-05-18 22:28:30,642 INFO: 1 batches, avg len: 15.7\n",
      "2019-05-18 22:28:31,700 INFO: 1 batches, avg len: 22.6\n",
      "2019-05-18 22:28:33,542 INFO: 1 batches, avg len: 20.1\n",
      "2019-05-18 22:28:35,172 INFO: 1 batches, avg len: 20.7\n",
      "2019-05-18 22:28:36,725 INFO: 1 batches, avg len: 24.6\n",
      "2019-05-18 22:28:38,582 INFO: 1 batches, avg len: 18.4\n",
      "2019-05-18 22:28:39,986 INFO: 1 batches, avg len: 18.0\n",
      "2019-05-18 22:28:41,115 INFO: 1 batches, avg len: 22.1\n",
      "2019-05-18 22:28:42,785 INFO: 1 batches, avg len: 14.9\n",
      "2019-05-18 22:28:43,702 INFO: 1 batches, avg len: 17.4\n",
      "2019-05-18 22:28:44,895 INFO: 1 batches, avg len: 17.9\n",
      "2019-05-18 22:28:46,243 INFO: 1 batches, avg len: 20.6\n",
      "2019-05-18 22:28:47,673 INFO: 1 batches, avg len: 19.5\n",
      "2019-05-18 22:28:49,096 INFO: 1 batches, avg len: 24.7\n",
      "2019-05-18 22:28:50,775 INFO: 1 batches, avg len: 35.9\n",
      "2019-05-18 22:28:53,330 INFO: 1 batches, avg len: 24.2\n",
      "2019-05-18 22:28:55,056 INFO: 1 batches, avg len: 21.3\n",
      "2019-05-18 22:28:56,859 INFO: 1 batches, avg len: 22.3\n",
      "2019-05-18 22:28:58,396 INFO: 1 batches, avg len: 22.4\n",
      "2019-05-18 22:28:59,823 INFO: 1 batches, avg len: 20.5\n",
      "2019-05-18 22:29:01,250 INFO: 1 batches, avg len: 26.2\n",
      "2019-05-18 22:29:04,368 INFO: 1 batches, avg len: 25.5\n",
      "2019-05-18 22:29:06,114 INFO: 1 batches, avg len: 22.1\n",
      "2019-05-18 22:29:07,898 INFO: 1 batches, avg len: 29.4\n",
      "2019-05-18 22:29:09,762 INFO: 1 batches, avg len: 20.9\n",
      "2019-05-18 22:29:11,537 INFO: 1 batches, avg len: 23.5\n",
      "2019-05-18 22:29:13,385 INFO: 1 batches, avg len: 19.7\n",
      "2019-05-18 22:29:14,797 INFO: 1 batches, avg len: 21.8\n",
      "2019-05-18 22:29:16,444 INFO: 1 batches, avg len: 21.5\n",
      "2019-05-18 22:29:17,713 INFO: 1 batches, avg len: 20.7\n",
      "2019-05-18 22:29:19,063 INFO: 1 batches, avg len: 24.0\n",
      "2019-05-18 22:29:20,911 INFO: 1 batches, avg len: 16.7\n",
      "2019-05-18 22:29:22,590 INFO: 1 batches, avg len: 14.2\n",
      "2019-05-18 22:29:23,908 INFO: 1 batches, avg len: 15.9\n",
      "2019-05-18 22:29:25,334 INFO: 1 batches, avg len: 26.5\n",
      "2019-05-18 22:29:27,043 INFO: 1 batches, avg len: 24.0\n",
      "2019-05-18 22:29:28,927 INFO: 1 batches, avg len: 20.1\n",
      "2019-05-18 22:29:30,540 INFO: 1 batches, avg len: 21.6\n",
      "2019-05-18 22:29:32,438 INFO: 1 batches, avg len: 15.1\n",
      "2019-05-18 22:29:33,487 INFO: 1 batches, avg len: 24.5\n",
      "2019-05-18 22:29:36,137 INFO: 1 batches, avg len: 19.5\n",
      "2019-05-18 22:29:37,801 INFO: 1 batches, avg len: 14.1\n",
      "2019-05-18 22:29:38,771 INFO: 1 batches, avg len: 18.6\n",
      "2019-05-18 22:29:40,050 INFO: 1 batches, avg len: 25.7\n",
      "2019-05-18 22:29:41,876 INFO: 1 batches, avg len: 24.5\n",
      "2019-05-18 22:29:43,146 INFO: 1 batches, avg len: 18.4\n",
      "2019-05-18 22:29:45,092 INFO: 1 batches, avg len: 19.3\n",
      "2019-05-18 22:29:46,487 INFO: 1 batches, avg len: 19.1\n",
      "2019-05-18 22:29:47,757 INFO: 1 batches, avg len: 23.3\n",
      "2019-05-18 22:29:49,608 INFO: 1 batches, avg len: 27.6\n",
      "2019-05-18 22:29:51,943 INFO: 1 batches, avg len: 23.6\n",
      "2019-05-18 22:29:54,139 INFO: 1 batches, avg len: 18.4\n",
      "2019-05-18 22:29:55,405 INFO: 1 batches, avg len: 19.3\n",
      "2019-05-18 22:29:56,743 INFO: 1 batches, avg len: 22.9\n",
      "2019-05-18 22:29:57,979 INFO: 1 batches, avg len: 28.0\n",
      "2019-05-18 22:30:01,322 INFO: 1 batches, avg len: 25.8\n",
      "2019-05-18 22:30:03,376 INFO: 1 batches, avg len: 19.4\n",
      "2019-05-18 22:30:04,551 INFO: 1 batches, avg len: 21.4\n",
      "2019-05-18 22:30:06,385 INFO: 1 batches, avg len: 19.2\n",
      "2019-05-18 22:30:07,655 INFO: 1 batches, avg len: 21.4\n",
      "2019-05-18 22:30:09,569 INFO: 1 batches, avg len: 23.1\n",
      "2019-05-18 22:30:10,995 INFO: 1 batches, avg len: 22.2\n",
      "2019-05-18 22:30:12,941 INFO: 1 batches, avg len: 28.3\n",
      "2019-05-18 22:30:15,182 INFO: 1 batches, avg len: 22.5\n",
      "2019-05-18 22:30:16,467 INFO: 1 batches, avg len: 25.8\n",
      "2019-05-18 22:30:17,832 INFO: 1 batches, avg len: 18.5\n",
      "2019-05-18 22:30:19,226 INFO: 1 batches, avg len: 16.9\n",
      "2019-05-18 22:30:20,345 INFO: 1 batches, avg len: 16.8\n",
      "2019-05-18 22:30:21,501 INFO: 1 batches, avg len: 17.6\n",
      "2019-05-18 22:30:22,896 INFO: 1 batches, avg len: 16.5\n",
      "2019-05-18 22:30:24,073 INFO: 1 batches, avg len: 15.3\n",
      "2019-05-18 22:30:25,156 INFO: 1 batches, avg len: 15.9\n",
      "2019-05-18 22:30:26,221 INFO: 1 batches, avg len: 21.1\n",
      "2019-05-18 22:30:27,570 INFO: 1 batches, avg len: 22.9\n",
      "2019-05-18 22:30:29,608 INFO: 1 batches, avg len: 26.9\n",
      "2019-05-18 22:30:31,522 INFO: 1 batches, avg len: 22.7\n",
      "2019-05-18 22:30:33,183 INFO: 1 batches, avg len: 28.5\n",
      "2019-05-18 22:30:34,971 INFO: 1 batches, avg len: 20.3\n",
      "2019-05-18 22:30:36,538 INFO: 1 batches, avg len: 20.9\n",
      "2019-05-18 22:30:38,514 INFO: 1 batches, avg len: 21.6\n",
      "2019-05-18 22:30:40,364 INFO: 1 batches, avg len: 24.1\n",
      "2019-05-18 22:30:41,916 INFO: 1 batches, avg len: 16.5\n",
      "2019-05-18 22:30:42,951 INFO: 1 batches, avg len: 19.7\n",
      "2019-05-18 22:30:44,425 INFO: 1 batches, avg len: 16.9\n",
      "2019-05-18 22:30:45,522 INFO: 1 batches, avg len: 14.6\n",
      "2019-05-18 22:30:46,683 INFO: 1 batches, avg len: 20.9\n",
      "2019-05-18 22:30:48,252 INFO: 1 batches, avg len: 29.6\n",
      "2019-05-18 22:30:50,446 INFO: 1 batches, avg len: 21.9\n",
      "2019-05-18 22:30:52,282 INFO: 1 batches, avg len: 22.5\n",
      "2019-05-18 22:30:54,054 INFO: 1 batches, avg len: 18.5\n",
      "2019-05-18 22:30:55,259 INFO: 1 batches, avg len: 20.8\n",
      "2019-05-18 22:30:56,514 INFO: 1 batches, avg len: 24.4\n",
      "2019-05-18 22:30:59,546 INFO: 1 batches, avg len: 14.0\n",
      "2019-05-18 22:31:00,372 INFO: 1 batches, avg len: 23.5\n",
      "2019-05-18 22:31:02,050 INFO: 1 batches, avg len: 23.1\n",
      "2019-05-18 22:31:03,963 INFO: 1 batches, avg len: 18.3\n",
      "2019-05-18 22:31:05,296 INFO: 1 batches, avg len: 20.7\n",
      "2019-05-18 22:31:06,990 INFO: 1 batches, avg len: 15.9\n",
      "2019-05-18 22:31:08,119 INFO: 1 batches, avg len: 21.8\n",
      "2019-05-18 22:31:09,528 INFO: 1 batches, avg len: 18.1\n",
      "2019-05-18 22:31:11,066 INFO: 1 batches, avg len: 24.3\n",
      "2019-05-18 22:31:12,570 INFO: 1 batches, avg len: 18.0\n",
      "2019-05-18 22:31:13,969 INFO: 1 batches, avg len: 22.3\n",
      "2019-05-18 22:31:15,754 INFO: 1 batches, avg len: 19.5\n",
      "2019-05-18 22:31:17,089 INFO: 1 batches, avg len: 21.0\n",
      "2019-05-18 22:31:18,781 INFO: 1 batches, avg len: 19.8\n",
      "2019-05-18 22:31:20,288 INFO: 1 batches, avg len: 25.1\n",
      "2019-05-18 22:31:22,559 INFO: 1 batches, avg len: 21.3\n",
      "2019-05-18 22:31:23,987 INFO: 1 batches, avg len: 21.7\n",
      "2019-05-18 22:31:25,365 INFO: 1 batches, avg len: 25.9\n",
      "2019-05-18 22:31:27,202 INFO: 1 batches, avg len: 17.3\n",
      "2019-05-18 22:31:28,125 INFO: 1 batches, avg len: 18.2\n",
      "2019-05-18 22:31:29,506 INFO: 1 batches, avg len: 15.8\n",
      "2019-05-18 22:31:30,683 INFO: 1 batches, avg len: 14.7\n",
      "2019-05-18 22:31:31,811 INFO: 1 batches, avg len: 25.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-18 22:31:33,599 INFO: 1 batches, avg len: 17.5\n",
      "2019-05-18 22:31:34,665 INFO: 1 batches, avg len: 23.3\n",
      "2019-05-18 22:31:36,373 INFO: 1 batches, avg len: 22.3\n",
      "2019-05-18 22:31:38,005 INFO: 1 batches, avg len: 19.9\n",
      "2019-05-18 22:31:39,557 INFO: 1 batches, avg len: 23.1\n",
      "2019-05-18 22:31:41,359 INFO: 1 batches, avg len: 28.7\n",
      "2019-05-18 22:31:43,399 INFO: 1 batches, avg len: 24.9\n",
      "2019-05-18 22:31:44,872 INFO: 1 batches, avg len: 19.7\n",
      "2019-05-18 22:31:46,125 INFO: 1 batches, avg len: 19.2\n",
      "2019-05-18 22:31:47,915 INFO: 1 batches, avg len: 29.9\n",
      "2019-05-18 22:31:50,078 INFO: 1 batches, avg len: 21.0\n",
      "2019-05-18 22:31:51,630 INFO: 1 batches, avg len: 18.4\n",
      "2019-05-18 22:31:53,010 INFO: 1 batches, avg len: 27.7\n",
      "2019-05-18 22:31:54,923 INFO: 1 batches, avg len: 31.5\n",
      "2019-05-18 22:31:57,449 INFO: 1 batches, avg len: 23.4\n",
      "2019-05-18 22:31:59,141 INFO: 1 batches, avg len: 20.0\n",
      "2019-05-18 22:32:00,882 INFO: 1 batches, avg len: 20.5\n",
      "2019-05-18 22:32:02,096 INFO: 1 batches, avg len: 21.4\n",
      "2019-05-18 22:32:03,563 INFO: 1 batches, avg len: 21.1\n",
      "2019-05-18 22:32:05,068 INFO: 1 batches, avg len: 28.5\n",
      "2019-05-18 22:32:06,998 INFO: 1 batches, avg len: 24.5\n",
      "2019-05-18 22:32:08,758 INFO: 1 batches, avg len: 19.7\n",
      "2019-05-18 22:32:10,163 INFO: 1 batches, avg len: 20.8\n",
      "2019-05-18 22:32:11,858 INFO: 1 batches, avg len: 19.7\n",
      "2019-05-18 22:32:13,126 INFO: 1 batches, avg len: 19.3\n",
      "2019-05-18 22:32:14,383 INFO: 1 batches, avg len: 18.4\n",
      "2019-05-18 22:32:15,936 INFO: 1 batches, avg len: 23.7\n",
      "2019-05-18 22:32:17,998 INFO: 1 batches, avg len: 26.7\n",
      "2019-05-18 22:32:19,872 INFO: 1 batches, avg len: 6.3\n"
     ]
    }
   ],
   "source": [
    "texts_train2 = elmo_convert_to_vectors(elmo_model, texts_train2)\n",
    "texts_test2 = elmo_convert_to_vectors(elmo_model, texts_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_dataset_train2 = NERDataset(texts_train2, labels_train2, elmo_embedding_size)\n",
    "texts_train_loader2 = torch.utils.data.DataLoader(texts_dataset_train2, batch_size = batch_size)\n",
    "\n",
    "texts_dataset_test2 = NERDataset(texts_test2, None, elmo_embedding_size)\n",
    "texts_test_loader2 = torch.utils.data.DataLoader(texts_dataset_test2, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm_crf2 = BiLSTM_CRF(embed_size = elmo_embedding_size, \n",
    "                         hidden_dim = 10, \n",
    "                         num_tag = 7,\n",
    "                         batch_first = True)\n",
    "\n",
    "bilstm_crf2.type(torch.cuda.FloatTensor)\n",
    "bilstm_crf2.to(device)\n",
    "\n",
    "optimizer2 = optim.RMSprop(bilstm_crf2.parameters(), lr = 1e-2, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load the standard of book_3954:\n",
      "Unknown mention tag: Facility\n",
      "Type    P        R        F1       TP1      TP2      In Std.  In Test.\n",
      "per        0.9118   0.8621   0.8863  1155.25  1155.25     1340     1267\n",
      "loc        0.9039   0.8627   0.8828  1058.50  1058.50     1227     1171\n",
      "org        0.7350   0.6486   0.6891  1020.88  1020.88     1574     1389\n",
      "overall    0.8452   0.7811   0.8119  3234.63  3234.63     4141     3827\n",
      "Wall time: 5min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_model(bilstm_crf2, texts_train_loader2, optimizer2, num_epochs = 20)\n",
    "\n",
    "prediction2 = predict(bilstm_crf2, texts_test_loader2)\n",
    "\n",
    "create_file_eval('data/testset/', 'data/eval/', books_name, prediction2)\n",
    "\n",
    "!python scripts/t1_eval.py -s data/testset -t data/eval -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-NLP",
   "language": "python",
   "name": "pytorch-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
